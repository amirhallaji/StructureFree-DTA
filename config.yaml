# Drug-Target Interaction Model Configuration

# Model Configuration
model:
  protein_model_name: "facebook/esm2_t6_8M_UR50D"
  molecule_model_name: "DeepChem/ChemBERTa-77M-MLM"
  hidden_sizes: [1024, 768, 512, 256, 1]
  inception_out_channels: 256
  dropout: 0.05

# Data Configuration
data:
  train_data_path: "data/train.csv"
  val_data_path: "data/val.csv"
  test_data_path: null
  batch_size: 8
  num_workers: 4
  max_molecule_length: 16
  max_protein_length: 32

# Training Configuration
training:
  max_epochs: 100
  learning_rate: 1.0e-4
  weight_decay: 1.0e-6
  loss_alpha: 0.5
  gradient_clip_val: 1.0
  accumulate_grad_batches: 2
  precision: "16-mixed"  # Options: "32", "16-mixed", "bf16-mixed"
  
  # Early stopping configuration
  early_stopping_patience: 10  # Number of epochs with no improvement after which training will be stopped
  early_stopping_monitor: "val_loss"  # Metric to monitor for early stopping
  early_stopping_mode: "min"  # Mode for monitoring (min or max)
  
  # Learning rate scheduler
  lr_scheduler_factor: 0.5
  lr_scheduler_patience: 5
  lr_scheduler_min_lr: 1.0e-7

# Logging Configuration
logging:
  log_dir: "logs"
  save_dir: "checkpoints"
  experiment_name: "drug_target_interaction"
  log_every_n_steps: 50

# Other Configuration
seed: 42
accelerator: "auto"  # Options: "auto", "cpu", "gpu", "tpu", "mps"
devices: "auto"      # Number of devices or "auto"
strategy: "auto"     # Options: "auto", "ddp", "deepspeed", "fsdp" 